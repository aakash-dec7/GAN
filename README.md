# GAN

## Overview
This project demonstrates a Generative Adversarial Network (GAN) architecture to generate realistic images. The model employs a **Generator** to create synthetic images and a **Discriminator** to differentiate between real and generated images, training them adversarially.

The project is implemented using PyTorch and trained on a subset of the CIFAR-10 dataset.

## Features
- **Customizable Hyperparameters**: Modify batch size, learning rate, number of epochs, etc.
- **Efficient Training**: Uses adversarial loss for dynamic optimization of Generator and Discriminator.
- **Data Preprocessing**: Includes normalization and subset creation for efficient training.
- **Checkpointing**: Save and load model checkpoints to resume training seamlessly.
- **Visualization**: Generates sample images at regular intervals for monitoring model performance.


## Dataset
The model uses the **CIFAR-10 dataset**, which contains 60,000 32x32 color images across 10 classes. A subset of 2,500 images was randomly sampled for training to reduce computational load.

- Images are normalized to a range of [-1, 1].
- A subset of 2,500 images is randomly selected for faster training.
- A data loader is employed for batching and shuffling.

## Architecture
The model consists of the following components:

**1. Generator**
- Input: Latent vector of size `LATENT_DIM`.
- Layers:
  1. Fully connected layer, reshaped to initial feature map.
  2. Two upsampling blocks with convolution, batch normalization, and activation.
  3. Final convolution layer outputs RGB images with a `Tanh` activation.
- Output: 32x32x3 image tensor.

**2. Discriminator**
- Input: RGB image tensor (32x32x3).
- Layers:
  1. Convolutional blocks with downsampling, batch normalization, and `LeakyReLU`.
  2. Fully connected layer followed by a `Sigmoid` activation.
- Output: Scalar probability indicating whether the image is real or fake.

## Hyperparameters
Adjust these to customise your training:
- **Batch Size**: 64
- **Latent Dimension**: 256
- **Learning Rate**: 0.005
- **Beta1**: 0.5
- **Beta2**: 0.99
- **Number of Epochs**: 250

## Training Workflow
**1. Discriminator Training**:
   - Trains on both real images and fake images generated by the Generator.
   - Computes separate losses for real and fake images.

**2. Generator Training**:
   - Trains to create images that maximize the Discriminator's misclassification.
   - Uses adversarial loss to guide optimization.

## Contributions
Feel free to fork the repository and submit a pull request for improvements.

## License
This project is licensed under the MIT License.
